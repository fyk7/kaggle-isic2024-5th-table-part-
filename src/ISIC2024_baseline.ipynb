{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "eLliTdGknNwr"
      },
      "outputs": [],
      "source": [
        "from google.colab import auth\n",
        "auth.authenticate_user()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xRBpVEaq6Sa-",
        "outputId": "9a817951-48fe-433d-8712-986cbb590828"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ]
        }
      ],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "CGd-XhYa3qno"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "# os.environ[\"CUDA_VISIBLE_DEVICES\"]=\"0,1\"\n",
        "\n",
        "COMMON_DIR=\"/content/drive/MyDrive/kaggle/isic2024_v3\"\n",
        "ONLY_ONE_FOLD = False\n",
        "TEST_RUN = False\n",
        "TARGET_EXP_VERS = [1]\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "id": "h8-Ux_YE6GHE"
      },
      "outputs": [],
      "source": [
        "# !pip install datasets >> /dev/null\n",
        "!pip install accelerate -U >> /dev/null\n",
        "!pip install timm colorama albumentations -U >> /dev/null\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "id": "dOdEZzyW3qno"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "import gc\n",
        "import cv2\n",
        "import math\n",
        "import copy\n",
        "import time\n",
        "import random\n",
        "import glob\n",
        "from matplotlib import pyplot as plt\n",
        "\n",
        "# For data manipulation\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "\n",
        "# Pytorch Imports\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "import torch.nn.functional as F\n",
        "from torch.optim import lr_scheduler\n",
        "from torch.utils.data import Dataset, DataLoader\n",
        "from torch.cuda import amp\n",
        "import torchvision\n",
        "# from torcheval.metrics.functional import binary_auroc\n",
        "\n",
        "# Utils\n",
        "import joblib\n",
        "from tqdm import tqdm\n",
        "from collections import defaultdict\n",
        "\n",
        "# Sklearn Imports\n",
        "from sklearn.preprocessing import LabelEncoder\n",
        "from sklearn.model_selection import StratifiedKFold, StratifiedGroupKFold\n",
        "\n",
        "# For Image Models\n",
        "import timm\n",
        "\n",
        "# Albumentations for augmentations\n",
        "import albumentations as A\n",
        "from albumentations.pytorch import ToTensorV2\n",
        "\n",
        "# For colored terminal text\n",
        "from colorama import Fore, Back, Style\n",
        "b_ = Fore.BLUE\n",
        "sr_ = Style.RESET_ALL\n",
        "\n",
        "import warnings\n",
        "warnings.filterwarnings(\"ignore\")\n",
        "\n",
        "# For descriptive error messages\n",
        "os.environ['CUDA_LAUNCH_BLOCKING'] = \"1\"\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "id": "70xQr9AnnDu2"
      },
      "outputs": [],
      "source": [
        "# GSSからハイパラ設定等を読み込んでCFGクラスに登録する\n",
        "import gspread\n",
        "from gspread_dataframe import get_as_dataframe, set_with_dataframe\n",
        "from google.auth import default\n",
        "creds, _ = default()\n",
        "gc = gspread.authorize(creds)\n",
        "\n",
        "url = \"https://docs.google.com/spreadsheets/d/1FoTSNZKKb-T7zxGz7FVUrpfSiTyo1-Ix0XPR-ORbWsY/edit?gid=0#gid=0\"\n",
        "ss = gc.open_by_url(url)\n",
        "param_sheet = ss.worksheet(\"パラメータv1\")\n",
        "df_param = get_as_dataframe(param_sheet)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "id": "9-N2EUTGmZCa"
      },
      "outputs": [],
      "source": [
        "from pydantic import BaseModel\n",
        "from typing import Optional\n",
        "\n",
        "# default configs\n",
        "class CriterionCFG(BaseModel):\n",
        "    criterion_type: str = \"FocalLoss\"\n",
        "    focal_gamma: Optional[float] = 2.0\n",
        "\n",
        "\n",
        "class ModelCFG(BaseModel):\n",
        "    backbone_type: str = \"microsoft/deberta-v3-large\"\n",
        "    gradient_checkpointing: bool = False\n",
        "    pretrained: bool = True\n",
        "    pooling_type: str = \"MeanPooling\"\n",
        "    freeze_n_layers: Optional[int] = 0\n",
        "    reinitialize_n_layers: int = 0\n",
        "    criterion: Optional[CriterionCFG] = None\n",
        "\n",
        "\n",
        "class OptimizerCFG(BaseModel):\n",
        "    encoder_lr: Optional[float] = 1e-5\n",
        "    decoder_lr: Optional[float] = 1e-5\n",
        "    embeddings_lr: Optional[float] = 1e-5\n",
        "    weight_decay: Optional[float] = 0.01\n",
        "    eps: Optional[float] = 1e-8\n",
        "    betas: Optional[tuple] = (0.9, 0.999)\n",
        "\n",
        "\n",
        "class SchedulerCFG(BaseModel):\n",
        "    scheduler_type: str = \"linear\"\n",
        "    num_warmup_steps: Optional[int] = 0\n",
        "    num_cycles: Optional[float] = 0.5\n",
        "\n",
        "\n",
        "class CFG(BaseModel):\n",
        "    exp_ver: Optional[str] = \"v2\"\n",
        "    n_splits: Optional[int] = 5\n",
        "    seed: Optional[int] = 42\n",
        "    lr: Optional[float] = 1e-5\n",
        "    gradient_accumulation_steps: Optional[int] = 4\n",
        "    save_eval_step_base: Optional[int] = 10 # 小さいほどこまめにcheck pointを保存\n",
        "    train_batch_size: Optional[int] = 256\n",
        "    eval_batch_size: Optional[int] = 512\n",
        "    train_epochs: Optional[int] = 3\n",
        "    weight_decay: Optional[float] = 0.01\n",
        "    warmup_ratio: Optional[float] = 0.0\n",
        "    num_labels: Optional[int] = 1\n",
        "    fold_type: str = \"stratified\"\n",
        "    freeze_n_layers: Optional[int] = 6\n",
        "    scheduler_type: Optional[str] = \"linear\"\n",
        "    user_persuade_data: Optional[int] = 0\n",
        "    pool_type: Optional[str] = \"GeM\"\n",
        "    criterion_type: Optional[str] = \"FocalLoss\"\n",
        "    weight_decay: Optional[float] = 0.01\n",
        "    criterion: Optional[CriterionCFG] = None\n",
        "    optimizer: Optional[OptimizerCFG] = None\n",
        "    scheduler: Optional[SchedulerCFG] = None\n",
        "    model: Optional[ModelCFG] = None\n",
        "    tokenizer_emb_len: Optional[int] = None\n",
        "    use_prompt: Optional[int] = 0\n",
        "    use_task_token: Optional[int] = 0\n",
        "    save_pseudo_label: Optional[int] = 0\n",
        "    img_size: int = 224\n",
        "\n",
        "\n",
        "# configs from GSS\n",
        "all_config_list = []\n",
        "for exp_ver in TARGET_EXP_VERS:\n",
        "    cfg = CFG()\n",
        "    i = exp_ver - 1\n",
        "    cfg.exp_ver = int(exp_ver)\n",
        "    cfg.seed = int(df_param.loc[i, \"seed\"])\n",
        "    cfg.gradient_accumulation_steps = int(df_param.loc[i, \"gradient_accumulation_steps\"])\n",
        "    cfg.train_batch_size = int(df_param.loc[i, \"train_batch_size\"])\n",
        "    cfg.eval_batch_size = int(df_param.loc[i, \"eval_batch_size\"])\n",
        "    cfg.train_epochs = int(df_param.loc[i, \"train_epochs\"])\n",
        "    cfg.fold_type = str(df_param.loc[i, \"fold_type\"])\n",
        "    cfg.freeze_n_layers = int(df_param.loc[i, \"freeze_n_layers\"])\n",
        "    cfg.scheduler_type = str(df_param.loc[i, \"scheduler_type\"])\n",
        "    cfg.user_persuade_data = int(df_param.loc[i, \"user_persuade_data\"])\n",
        "    cfg.criterion_type = str(df_param.loc[i, \"criterion_type\"])\n",
        "    cfg.weight_decay = float(df_param.loc[i, \"weight_decay\"])\n",
        "    cfg.img_size = 224  # デフォルト値の設定\n",
        "\n",
        "    criterion_cfg = CriterionCFG()\n",
        "    criterion_cfg.criterion_type = str(df_param.loc[i, \"criterion_type\"])\n",
        "    criterion_cfg.focal_gamma = float(df_param.loc[i, \"focal_gamma\"])\n",
        "    cfg.criterion = criterion_cfg\n",
        "\n",
        "    model_cfg = ModelCFG()\n",
        "    model_cfg.backbone_type = str(df_param.loc[i, \"backbone_type\"])\n",
        "    model_cfg.pooling_type = str(df_param.loc[i, \"pooling_type\"])\n",
        "    model_cfg.freeze_n_layers = int(df_param.loc[i, \"freeze_n_layers\"])\n",
        "    model_cfg.reinitialize_n_layers = int(df_param.loc[i, \"reinitialize_n_layers\"])\n",
        "    cfg.model = model_cfg\n",
        "\n",
        "    optm_cfg = OptimizerCFG()\n",
        "    optm_cfg.encoder_lr = float(df_param.loc[i, \"encoder_lr\"])\n",
        "    optm_cfg.decoder_lr = float(df_param.loc[i, \"decoder_lr\"])\n",
        "    optm_cfg.embeddings_lr = float(df_param.loc[i, \"embeddings_lr\"])\n",
        "    optm_cfg.weight_decay = float(df_param.loc[i, \"weight_decay\"])\n",
        "    optm_cfg.eps = float(df_param.loc[i, \"eps\"])\n",
        "    optm_cfg.betas = (0.9, 0.999)  # デフォルト値の設定\n",
        "    cfg.optimizer = optm_cfg\n",
        "\n",
        "    scheduler_cfg = SchedulerCFG()\n",
        "    scheduler_cfg.scheduler_type = str(df_param.loc[i, \"scheduler_type\"])\n",
        "    scheduler_cfg.num_warmup_steps = 0  # デフォルト値の設定\n",
        "    scheduler_cfg.num_cycles = 0.5  # デフォルト値の設定\n",
        "    cfg.scheduler = scheduler_cfg\n",
        "\n",
        "    all_config_list.append(cfg)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 17,
      "metadata": {
        "id": "OQSSz6VX3qnp"
      },
      "outputs": [],
      "source": [
        "from pathlib import Path\n",
        "\n",
        "data_path = Path(COMMON_DIR)\n",
        "\n",
        "# TODO metadataを追加していく\n",
        "# (past_metadataという変数名をつけているがimgへのpathがメインで格納されているだけなのでpast_img_pathとrenameする)\n",
        "class PATHS:\n",
        "    past_img_path = data_path / \"past_metadata_df.csv\"\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def get_img_transform(CFG, is_train=False):\n",
        "    if is_train:\n",
        "        return A.Compose([\n",
        "            A.Resize(CFG.img_size, CFG.img_size),\n",
        "            A.RandomRotate90(p=0.5),\n",
        "            A.Flip(p=0.5),\n",
        "            A.Downscale(p=0.25),\n",
        "            A.ShiftScaleRotate(shift_limit=0.1, scale_limit=0.15, rotate_limit=60, p=0.5),\n",
        "            A.HueSaturationValue(hue_shift_limit=0.2, sat_shift_limit=0.2, val_shift_limit=0.2, p=0.5),\n",
        "            A.RandomBrightnessContrast(brightness_limit=(-0.1,0.1), contrast_limit=(-0.1, 0.1), p=0.5),\n",
        "            A.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225], max_pixel_value=255.0, p=1.0),\n",
        "            ToTensorV2()\n",
        "        ], p=1.)\n",
        "    else:\n",
        "        return A.Compose([\n",
        "            A.Resize(CFG.img_size, CFG.img_size),\n",
        "            A.Normalize(\n",
        "                mean=[0.485, 0.456, 0.406],\n",
        "                std=[0.229, 0.224, 0.225],\n",
        "                max_pixel_value=255.0,\n",
        "                p=1.0\n",
        "            ),\n",
        "            ToTensorV2()], p=1.)\n",
        "\n",
        "# TODO 試してみる\n",
        "# 2020 1st Place Solution Transform Strategy\n",
        "def get_img_transform_v2(CFG, is_train=False):\n",
        "    if is_train:\n",
        "        return A.Compose([\n",
        "            A.Resize(CFG.img_size, CFG.img_size),\n",
        "            A.RandomRotate90(p=0.5),\n",
        "            A.Flip(p=0.5),\n",
        "            A.Downscale(p=0.25),\n",
        "            A.ShiftScaleRotate(shift_limit=0.1, scale_limit=0.15, rotate_limit=60, p=0.5),\n",
        "            A.HueSaturationValue(hue_shift_limit=0.2, sat_shift_limit=0.2, val_shift_limit=0.2, p=0.5),\n",
        "            A.RandomBrightnessContrast(brightness_limit=(-0.1,0.1), contrast_limit=(-0.1, 0.1), p=0.5),\n",
        "            A.OneOf([\n",
        "                A.MotionBlur(blur_limit=5),\n",
        "                A.MedianBlur(blur_limit=5),\n",
        "                A.GaussianBlur(blur_limit=5),\n",
        "                A.GaussNoise(var_limit=(5.0, 30.0)),\n",
        "            ], p=0.7),\n",
        "            A.OneOf([\n",
        "                A.OpticalDistortion(distort_limit=1.0),\n",
        "                A.GridDistortion(num_steps=5, distort_limit=1.),\n",
        "                A.ElasticTransform(alpha=3),\n",
        "            ], p=0.7),\n",
        "            A.CLAHE(clip_limit=4.0, p=0.7),\n",
        "            A.HueSaturationValue(hue_shift_limit=10, sat_shift_limit=20, val_shift_limit=10, p=0.5),\n",
        "            A.ShiftScaleRotate(shift_limit=0.1, scale_limit=0.1, rotate_limit=15, border_mode=0, p=0.85),\n",
        "            A.Cutout(max_h_size=int(CFG.img_size * 0.375), max_w_size=int(CFG.img_size * 0.375), num_holes=1, p=0.7),\n",
        "            A.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225], max_pixel_value=255.0, p=1.0),\n",
        "            ToTensorV2()\n",
        "        ], p=1.)\n",
        "    else:\n",
        "        return A.Compose([\n",
        "            A.Resize(CFG.img_size, CFG.img_size),\n",
        "            A.Normalize(\n",
        "                mean=[0.485, 0.456, 0.406],\n",
        "                std=[0.229, 0.224, 0.225],\n",
        "                max_pixel_value=255.0,\n",
        "                p=1.0\n",
        "            ),\n",
        "            ToTensorV2()\n",
        "        ], p=1.)\n"
      ],
      "metadata": {
        "id": "fCoi6XvPT1mf"
      },
      "execution_count": 18,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import random\n",
        "import cv2\n",
        "from torch.utils.data import Dataset\n",
        "\n",
        "\n",
        "# TODO metadata特徴量を追加する\n",
        "class ISICDataset(Dataset):\n",
        "    def __init__(self, df, is_train=False, transforms=None):\n",
        "        self.is_train = is_train\n",
        "        self.df = df.reset_index(drop=True)\n",
        "        self.file_names = df['file_path'].values\n",
        "        self.targets = df['target'].values\n",
        "        self.transforms = transforms\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.df)\n",
        "\n",
        "    def __getitem__(self, index):\n",
        "        img_path = self.file_names[index]\n",
        "        img = cv2.imread(img_path)\n",
        "        img = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)\n",
        "        target = self.targets[index]\n",
        "\n",
        "        if self.transforms:\n",
        "            img = self.transforms(image=img)[\"image\"]\n",
        "\n",
        "        return {\n",
        "            'image': img,\n",
        "            'target': target\n",
        "        }\n"
      ],
      "metadata": {
        "id": "RsQB4R6MTb8g"
      },
      "execution_count": 19,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "from torch.nn.parameter import Parameter\n",
        "import numpy as np\n",
        "\n",
        "\n",
        "class GeM(nn.Module):\n",
        "    def __init__(self, p=3, eps=1e-6):\n",
        "        super(GeM, self).__init__()\n",
        "        self.p = nn.Parameter(torch.ones(1)*p)\n",
        "        self.eps = eps\n",
        "\n",
        "    def forward(self, x):\n",
        "        return self.gem(x, p=self.p, eps=self.eps)\n",
        "\n",
        "    def gem(self, x, p=3, eps=1e-6):\n",
        "        return F.avg_pool2d(x.clamp(min=eps).pow(p), (x.size(-2), x.size(-1))).pow(1./p)\n",
        "\n",
        "    def __repr__(self):\n",
        "        return self.__class__.__name__ + \\\n",
        "                '(' + 'p=' + '{:.4f}'.format(self.p.data.tolist()[0]) + \\\n",
        "                ', ' + 'eps=' + str(self.eps) + ')'\n",
        "\n",
        "\n",
        "# TODO Pooling Strategyを追加していく\n",
        "def get_pooling_layer(pooling_type: str = \"GeM\"):\n",
        "    if pooling_type == 'GeM':\n",
        "        return GeM()\n",
        "    elif pooling_type == 'AdaptiveAvgPool2d':\n",
        "        return nn.AdaptiveAvgPool2d(1)\n",
        "    elif pooling_type == 'AdaptiveMaxPool2d':\n",
        "        return nn.AdaptiveMaxPool2d(1)\n",
        "    else:\n",
        "        raise ValueError(f'Invalid pooling type: {pooling_type}')\n",
        "\n",
        "\n",
        "def freeze(module):\n",
        "    for parameter in module.parameters():\n",
        "        parameter.requires_grad = False\n",
        "\n",
        "\n",
        "# TODO sigmoid通す必要があるかを再度検討\n",
        "class ISICModel(nn.Module):\n",
        "    def __init__(\n",
        "        self,\n",
        "        backbone_type: str,\n",
        "        pooling_type: str = \"GeM\",\n",
        "        num_classes=1,\n",
        "        pretrained=True,\n",
        "        checkpoint_path=None,\n",
        "        use_metadata=False,\n",
        "    ):\n",
        "        super(ISICModel, self).__init__()\n",
        "        self.backbone = timm.create_model(\n",
        "            backbone_type,\n",
        "            pretrained=pretrained,\n",
        "            checkpoint_path=checkpoint_path,\n",
        "        )\n",
        "\n",
        "        in_features = self.backbone.head.in_features\n",
        "        self.backbone.head = nn.Identity()\n",
        "        self.backbone.global_pool = nn.Identity()\n",
        "        self.pooling = get_pooling_layer(pooling_type)\n",
        "        self.linear = nn.Linear(in_features, num_classes)\n",
        "\n",
        "    # input_ids, attention_mask, token_type_idsはTrainerを使用するためのdummy\n",
        "    def forward(\n",
        "        self,\n",
        "        input_ids=None,\n",
        "        attention_mask=None,\n",
        "        token_type_ids=None,\n",
        "        images=None,\n",
        "        labels=None,\n",
        "        **kwargs,\n",
        "    ):\n",
        "        features = self.backbone(images)\n",
        "        pooled_features = self.pooling(features).flatten(1)\n",
        "        logits = self.linear(pooled_features)\n",
        "        return {\"logits\": logits}\n"
      ],
      "metadata": {
        "id": "1QTmWxy9QOFe"
      },
      "execution_count": 20,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "\n",
        "\n",
        "# TODO Custom lossを追加していく\n",
        "class BinaryFocalLoss(torch.nn.Module):\n",
        "    def __init__(self, weight: torch.Tensor | None = None, gamma: float = 2, reduction: str = 'mean') -> None:\n",
        "        super().__init__()\n",
        "        self.gamma = gamma\n",
        "        self.weight = weight\n",
        "        self.reduction = reduction\n",
        "\n",
        "    def forward(self, input: torch.Tensor, target: torch.Tensor) -> torch.Tensor:\n",
        "        bce_loss = F.binary_cross_entropy_with_logits(input, target, weight=self.weight, reduction='none')\n",
        "        pt = torch.exp(-bce_loss)\n",
        "        focal_loss = (1 - pt) ** self.gamma * bce_loss\n",
        "\n",
        "        if self.reduction == 'mean':\n",
        "            return torch.mean(focal_loss)\n",
        "        elif self.reduction == 'sum':\n",
        "            return torch.sum(focal_loss)\n",
        "        else:\n",
        "            return focal_loss\n",
        "\n",
        "\n",
        "def get_criterion(config):\n",
        "    if config.criterion.criterion_type == 'FocalLoss':\n",
        "        return BinaryFocalLoss(gamma=2.0)\n",
        "    # else:\n",
        "    #     raise ValueError(f\"Unsupported loss function: {config.criterion.criterion_type}\")\n",
        "\n",
        "    return nn.MSELoss()\n"
      ],
      "metadata": {
        "id": "k5ORwtdCPgEz"
      },
      "execution_count": 21,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import math\n",
        "from transformers import (\n",
        "    get_linear_schedule_with_warmup,\n",
        "    get_cosine_schedule_with_warmup,\n",
        "    get_polynomial_decay_schedule_with_warmup,\n",
        "    get_constant_schedule_with_warmup\n",
        ")\n",
        "from torch.optim import AdamW\n",
        "# from torchcontrib.optim import SWA\n",
        "\n",
        "\n",
        "def get_optimizer_params(model, encoder_lr, decoder_lr, weight_decay=0.0):\n",
        "    no_decay = [\"bias\", \"LayerNorm.bias\", \"LayerNorm.weight\"]\n",
        "    optimizer_parameters = [\n",
        "        {\n",
        "            'params': [p for n, p in model.backbone.named_parameters() if not any(nd in n for nd in no_decay)],\n",
        "            'lr': encoder_lr,\n",
        "            'weight_decay': weight_decay\n",
        "        },\n",
        "        {\n",
        "            'params': [p for n, p in model.backbone.named_parameters() if any(nd in n for nd in no_decay)],\n",
        "            'lr': encoder_lr,\n",
        "            'weight_decay': 0.0\n",
        "        },\n",
        "        {\n",
        "            'params': [p for n, p in model.named_parameters() if \"backbone\" not in n],\n",
        "            'lr': decoder_lr,\n",
        "            'weight_decay': 0.0\n",
        "        }\n",
        "    ]\n",
        "    return optimizer_parameters\n",
        "\n",
        "\n",
        "def get_optimizer(model, config):\n",
        "    optimizer_parameters = get_optimizer_params(\n",
        "        model,\n",
        "        config.optimizer.encoder_lr,\n",
        "        config.optimizer.decoder_lr,\n",
        "        weight_decay=config.optimizer.weight_decay\n",
        "    )\n",
        "    optimizer = AdamW(\n",
        "        optimizer_parameters,\n",
        "        lr=config.optimizer.encoder_lr,\n",
        "        eps=config.optimizer.eps,\n",
        "        betas=config.optimizer.betas\n",
        "    )\n",
        "\n",
        "    # if config.optimizer.use_swa:\n",
        "    #     optimizer = SWA(\n",
        "    #         optimizer,\n",
        "    #         swa_start=config.optimizer.swa.swa_start,\n",
        "    #         swa_freq=config.optimizer.swa.swa_freq,\n",
        "    #         swa_lr=config.optimizer.swa.swa_lr\n",
        "    #     )\n",
        "\n",
        "    return optimizer\n",
        "\n",
        "def get_scheduler(optimizer, config, num_train_steps):\n",
        "    scheduler_type = config.scheduler.scheduler_type\n",
        "\n",
        "    if scheduler_type == 'constant_schedule_with_warmup':\n",
        "        scheduler = get_constant_schedule_with_warmup(\n",
        "            optimizer,\n",
        "            # num_warmup_steps=config.scheduler.constant_schedule_with_warmup.n_warmup_steps\n",
        "            num_warmup_steps=0\n",
        "        )\n",
        "    elif scheduler_type == 'linear_schedule_with_warmup':\n",
        "        scheduler = get_linear_schedule_with_warmup(\n",
        "            optimizer,\n",
        "            # num_warmup_steps=config.scheduler.linear_schedule_with_warmup.n_warmup_steps,\n",
        "            num_warmup_steps=0,\n",
        "            num_training_steps=num_train_steps\n",
        "        )\n",
        "    elif scheduler_type == 'cosine_schedule_with_warmup':\n",
        "        scheduler = get_cosine_schedule_with_warmup(\n",
        "            optimizer,\n",
        "            # num_warmup_steps=config.scheduler.cosine_schedule_with_warmup.n_warmup_steps,\n",
        "            num_warmup_steps=0,\n",
        "            # num_cycles=config.scheduler.cosine_schedule_with_warmup.n_cycles,\n",
        "            num_cycles=0.5,\n",
        "            num_training_steps=num_train_steps,\n",
        "        )\n",
        "    elif scheduler_type == 'polynomial_decay_schedule_with_warmup':\n",
        "        scheduler = get_polynomial_decay_schedule_with_warmup(\n",
        "            optimizer,\n",
        "            # num_warmup_steps=config.scheduler.polynomial_decay_schedule_with_warmup.n_warmup_steps,\n",
        "            num_warmup_steps=0,\n",
        "            num_training_steps=num_train_steps,\n",
        "            power=config.scheduler.polynomial_decay_schedule_with_warmup.power,\n",
        "            lr_end=config.scheduler.polynomial_decay_schedule_with_warmup.min_lr\n",
        "        )\n",
        "    else:\n",
        "        raise ValueError(f'Unknown scheduler: {scheduler_type}')\n",
        "\n",
        "    return scheduler\n"
      ],
      "metadata": {
        "id": "ci1ewsx1P8py"
      },
      "execution_count": 22,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": 23,
      "metadata": {
        "id": "ThfZQ4rZ3qnq"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "from sklearn.metrics import roc_curve, auc\n",
        "\n",
        "\n",
        "# TODO min, max scaleしているあたりが正しいか再度確認\n",
        "def calculate_pAUC(y_true, y_scores, min_tpr=0.8):\n",
        "    fpr, tpr, thresholds = roc_curve(y_true, y_scores)\n",
        "\n",
        "    mask = tpr >= min_tpr\n",
        "    fpr_partial = fpr[mask]\n",
        "    tpr_partial = tpr[mask]\n",
        "\n",
        "    fpr_partial = (fpr_partial - fpr_partial.min()) / (fpr_partial.max() - fpr_partial.min())\n",
        "    tpr_partial = (tpr_partial - tpr_partial.min()) / (tpr_partial.max() - tpr_partial.min())\n",
        "\n",
        "    pAUC = auc(fpr_partial, tpr_partial)\n",
        "\n",
        "    # Scale the pAUC to be in the range [0.0, 0.2]\n",
        "    pAUC_scaled = pAUC * 0.2\n",
        "\n",
        "    return pAUC_scaled\n",
        "\n",
        "\n",
        "def compute_metrics(eval_pred):\n",
        "    y_scores, y_true  = eval_pred[0], eval_pred[1]\n",
        "    return {'pAUC80': calculate_pAUC(y_true, y_scores)}\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from transformers import Trainer, TrainingArguments\n",
        "\n",
        "\n",
        "class CustomTrainer(Trainer):\n",
        "    def __init__(self, cfg, *args, **kwargs):\n",
        "        super().__init__(*args, **kwargs)\n",
        "        self.cfg = cfg\n",
        "        self.loss_fct = get_criterion(cfg)\n",
        "\n",
        "    def compute_loss(self, model, inputs, return_outputs=False):\n",
        "        labels = inputs.pop(\"labels\")\n",
        "        outputs = model(images=inputs.get(\"images\"))\n",
        "        logits = outputs.get(\"logits\")\n",
        "\n",
        "        loss = self.loss_fct(logits, labels)\n",
        "\n",
        "        return (loss, outputs) if return_outputs else loss\n",
        "\n",
        "\n",
        "def collate_fn(batch):\n",
        "    images = []\n",
        "    labels = []\n",
        "\n",
        "    for item in batch:\n",
        "        images.append(torch.tensor(item['image']).float())\n",
        "        labels.append(item['target'])\n",
        "\n",
        "    images = torch.stack(images)\n",
        "    labels = torch.tensor(labels).unsqueeze(1).float()\n",
        "\n",
        "    return {'images': images, 'labels': labels}\n",
        "\n"
      ],
      "metadata": {
        "id": "NH9JG7wxPqLL"
      },
      "execution_count": 24,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def seed_everything(seed):\n",
        "    import random, os\n",
        "    import numpy as np\n",
        "    import torch\n",
        "\n",
        "    random.seed(seed)\n",
        "    os.environ['PYTHONHASHSEED'] = str(seed)\n",
        "    np.random.seed(seed)\n",
        "    torch.manual_seed(seed)\n",
        "    torch.cuda.manual_seed(seed)\n",
        "    torch.backends.cudnn.deterministic = True\n",
        "    torch.backends.cudnn.benchmark = True\n",
        "\n",
        "seed_everything(seed=42)\n",
        "\n",
        "\n",
        "data = pd.read_csv(PATHS.past_img_path).sample(frac=0.5).reset_index(drop=True)\n",
        "# ISIC2024_prep_v2.ipynbでのdownload & uploadがcolab上で不安定でimageが存在しない場合があるため\n",
        "data['file_exists'] = data['file_path'].apply(lambda x: os.path.exists(x))\n",
        "data = data[data['file_exists']].drop(columns=['file_exists'])\n",
        "data[\"target\"] = data[\"target\"].astype('int32')\n",
        "\n"
      ],
      "metadata": {
        "id": "O1JaGiHzI5v2"
      },
      "execution_count": 25,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "data.head()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 226
        },
        "id": "5EHn5OkUKWS_",
        "outputId": "44e9cef4-8468-40d4-e567-33eeaf481800"
      },
      "execution_count": 26,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "        isic_id   patient_id  target  img_size  year  \\\n",
              "0  ISIC_0029222  HAM_0003615       0       224  2018   \n",
              "2  ISIC_0057102  dummy_15181       0       224  2019   \n",
              "4  ISIC_0030087   dummy_8684       0       224  2019   \n",
              "5  ISIC_0059171  dummy_16472       1       224  2019   \n",
              "7  ISIC_0025334   dummy_3931       0       224  2019   \n",
              "\n",
              "                                           file_path  skf_fold_num_5_seed_7  \\\n",
              "0  /content/drive/MyDrive/kaggle/isic2024_v3/isic...                      2   \n",
              "2  /content/drive/MyDrive/kaggle/isic2024_v3/isic...                      0   \n",
              "4  /content/drive/MyDrive/kaggle/isic2024_v3/isic...                      1   \n",
              "5  /content/drive/MyDrive/kaggle/isic2024_v3/isic...                      2   \n",
              "7  /content/drive/MyDrive/kaggle/isic2024_v3/isic...                      0   \n",
              "\n",
              "   skf_fold_num_5_seed_42  skf_fold_num_5_seed_1000  \n",
              "0                       0                         4  \n",
              "2                       2                         2  \n",
              "4                       0                         3  \n",
              "5                       2                         2  \n",
              "7                       0                         2  "
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-136e1ae6-b1a1-41de-b3ad-67edf3af8708\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>isic_id</th>\n",
              "      <th>patient_id</th>\n",
              "      <th>target</th>\n",
              "      <th>img_size</th>\n",
              "      <th>year</th>\n",
              "      <th>file_path</th>\n",
              "      <th>skf_fold_num_5_seed_7</th>\n",
              "      <th>skf_fold_num_5_seed_42</th>\n",
              "      <th>skf_fold_num_5_seed_1000</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>ISIC_0029222</td>\n",
              "      <td>HAM_0003615</td>\n",
              "      <td>0</td>\n",
              "      <td>224</td>\n",
              "      <td>2018</td>\n",
              "      <td>/content/drive/MyDrive/kaggle/isic2024_v3/isic...</td>\n",
              "      <td>2</td>\n",
              "      <td>0</td>\n",
              "      <td>4</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>ISIC_0057102</td>\n",
              "      <td>dummy_15181</td>\n",
              "      <td>0</td>\n",
              "      <td>224</td>\n",
              "      <td>2019</td>\n",
              "      <td>/content/drive/MyDrive/kaggle/isic2024_v3/isic...</td>\n",
              "      <td>0</td>\n",
              "      <td>2</td>\n",
              "      <td>2</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>ISIC_0030087</td>\n",
              "      <td>dummy_8684</td>\n",
              "      <td>0</td>\n",
              "      <td>224</td>\n",
              "      <td>2019</td>\n",
              "      <td>/content/drive/MyDrive/kaggle/isic2024_v3/isic...</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>3</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5</th>\n",
              "      <td>ISIC_0059171</td>\n",
              "      <td>dummy_16472</td>\n",
              "      <td>1</td>\n",
              "      <td>224</td>\n",
              "      <td>2019</td>\n",
              "      <td>/content/drive/MyDrive/kaggle/isic2024_v3/isic...</td>\n",
              "      <td>2</td>\n",
              "      <td>2</td>\n",
              "      <td>2</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>7</th>\n",
              "      <td>ISIC_0025334</td>\n",
              "      <td>dummy_3931</td>\n",
              "      <td>0</td>\n",
              "      <td>224</td>\n",
              "      <td>2019</td>\n",
              "      <td>/content/drive/MyDrive/kaggle/isic2024_v3/isic...</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>2</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-136e1ae6-b1a1-41de-b3ad-67edf3af8708')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-136e1ae6-b1a1-41de-b3ad-67edf3af8708 button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-136e1ae6-b1a1-41de-b3ad-67edf3af8708');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "<div id=\"df-0eb0f8d9-89c1-4086-bb07-3add5a1fff73\">\n",
              "  <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-0eb0f8d9-89c1-4086-bb07-3add5a1fff73')\"\n",
              "            title=\"Suggest charts\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "     width=\"24px\">\n",
              "    <g>\n",
              "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
              "    </g>\n",
              "</svg>\n",
              "  </button>\n",
              "\n",
              "<style>\n",
              "  .colab-df-quickchart {\n",
              "      --bg-color: #E8F0FE;\n",
              "      --fill-color: #1967D2;\n",
              "      --hover-bg-color: #E2EBFA;\n",
              "      --hover-fill-color: #174EA6;\n",
              "      --disabled-fill-color: #AAA;\n",
              "      --disabled-bg-color: #DDD;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart {\n",
              "      --bg-color: #3B4455;\n",
              "      --fill-color: #D2E3FC;\n",
              "      --hover-bg-color: #434B5C;\n",
              "      --hover-fill-color: #FFFFFF;\n",
              "      --disabled-bg-color: #3B4455;\n",
              "      --disabled-fill-color: #666;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart {\n",
              "    background-color: var(--bg-color);\n",
              "    border: none;\n",
              "    border-radius: 50%;\n",
              "    cursor: pointer;\n",
              "    display: none;\n",
              "    fill: var(--fill-color);\n",
              "    height: 32px;\n",
              "    padding: 0;\n",
              "    width: 32px;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart:hover {\n",
              "    background-color: var(--hover-bg-color);\n",
              "    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "    fill: var(--button-hover-fill-color);\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart-complete:disabled,\n",
              "  .colab-df-quickchart-complete:disabled:hover {\n",
              "    background-color: var(--disabled-bg-color);\n",
              "    fill: var(--disabled-fill-color);\n",
              "    box-shadow: none;\n",
              "  }\n",
              "\n",
              "  .colab-df-spinner {\n",
              "    border: 2px solid var(--fill-color);\n",
              "    border-color: transparent;\n",
              "    border-bottom-color: var(--fill-color);\n",
              "    animation:\n",
              "      spin 1s steps(1) infinite;\n",
              "  }\n",
              "\n",
              "  @keyframes spin {\n",
              "    0% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "      border-left-color: var(--fill-color);\n",
              "    }\n",
              "    20% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    30% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    40% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    60% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    80% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "    90% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "  }\n",
              "</style>\n",
              "\n",
              "  <script>\n",
              "    async function quickchart(key) {\n",
              "      const quickchartButtonEl =\n",
              "        document.querySelector('#' + key + ' button');\n",
              "      quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n",
              "      quickchartButtonEl.classList.add('colab-df-spinner');\n",
              "      try {\n",
              "        const charts = await google.colab.kernel.invokeFunction(\n",
              "            'suggestCharts', [key], {});\n",
              "      } catch (error) {\n",
              "        console.error('Error during call to suggestCharts:', error);\n",
              "      }\n",
              "      quickchartButtonEl.classList.remove('colab-df-spinner');\n",
              "      quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n",
              "    }\n",
              "    (() => {\n",
              "      let quickchartButtonEl =\n",
              "        document.querySelector('#df-0eb0f8d9-89c1-4086-bb07-3add5a1fff73 button');\n",
              "      quickchartButtonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "    })();\n",
              "  </script>\n",
              "</div>\n",
              "\n",
              "    </div>\n",
              "  </div>\n"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "dataframe",
              "variable_name": "data",
              "summary": "{\n  \"name\": \"data\",\n  \"rows\": 15997,\n  \"fields\": [\n    {\n      \"column\": \"isic_id\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 14543,\n        \"samples\": [\n          \"ISIC_0029396\",\n          \"ISIC_0035158\",\n          \"ISIC_0003056_downsampled\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"patient_id\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 15620,\n        \"samples\": [\n          \"dummy_9975\",\n          \"HAM_0002775\",\n          \"HAM_0002717\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"target\",\n      \"properties\": {\n        \"dtype\": \"int32\",\n        \"num_unique_values\": 2,\n        \"samples\": [\n          1,\n          0\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"img_size\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0,\n        \"min\": 224,\n        \"max\": 224,\n        \"num_unique_values\": 1,\n        \"samples\": [\n          224\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"year\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0,\n        \"min\": 2018,\n        \"max\": 2019,\n        \"num_unique_values\": 2,\n        \"samples\": [\n          2019\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"file_path\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 15997,\n        \"samples\": [\n          \"/content/drive/MyDrive/kaggle/isic2024_v3/isic-2019-jpg-224x224-resized/train-image/image/ISIC_0033828.jpg\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"skf_fold_num_5_seed_7\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 1,\n        \"min\": 0,\n        \"max\": 4,\n        \"num_unique_values\": 5,\n        \"samples\": [\n          0\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"skf_fold_num_5_seed_42\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 1,\n        \"min\": 0,\n        \"max\": 4,\n        \"num_unique_values\": 5,\n        \"samples\": [\n          2\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"skf_fold_num_5_seed_1000\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 1,\n        \"min\": 0,\n        \"max\": 4,\n        \"num_unique_values\": 5,\n        \"samples\": [\n          2\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    }\n  ]\n}"
            }
          },
          "metadata": {},
          "execution_count": 26
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "P4JiqQ-vGi9D",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "6aff24ad-c6f4-4dbc-f0ff-393705d73e82"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "5\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "    <div>\n",
              "      \n",
              "      <progress value='300' max='300' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
              "      [300/300 1:16:08, Epoch 3/3]\n",
              "    </div>\n",
              "    <table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              " <tr style=\"text-align: left;\">\n",
              "      <th>Step</th>\n",
              "      <th>Training Loss</th>\n",
              "      <th>Validation Loss</th>\n",
              "      <th>Pauc80</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <td>5</td>\n",
              "      <td>0.114800</td>\n",
              "      <td>0.957730</td>\n",
              "      <td>0.112596</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>10</td>\n",
              "      <td>0.114800</td>\n",
              "      <td>0.253085</td>\n",
              "      <td>0.090412</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>15</td>\n",
              "      <td>0.114800</td>\n",
              "      <td>0.687110</td>\n",
              "      <td>0.112000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>20</td>\n",
              "      <td>0.114800</td>\n",
              "      <td>0.158667</td>\n",
              "      <td>0.110512</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>25</td>\n",
              "      <td>0.114800</td>\n",
              "      <td>0.169035</td>\n",
              "      <td>0.106527</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>30</td>\n",
              "      <td>0.114800</td>\n",
              "      <td>0.128480</td>\n",
              "      <td>0.111672</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>35</td>\n",
              "      <td>0.114800</td>\n",
              "      <td>0.130745</td>\n",
              "      <td>0.116207</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>40</td>\n",
              "      <td>0.114800</td>\n",
              "      <td>0.134911</td>\n",
              "      <td>0.116063</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>45</td>\n",
              "      <td>0.114800</td>\n",
              "      <td>0.134423</td>\n",
              "      <td>0.116901</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>50</td>\n",
              "      <td>0.114800</td>\n",
              "      <td>0.130075</td>\n",
              "      <td>0.115518</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>55</td>\n",
              "      <td>0.114800</td>\n",
              "      <td>0.123853</td>\n",
              "      <td>0.121026</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>60</td>\n",
              "      <td>0.114800</td>\n",
              "      <td>0.123850</td>\n",
              "      <td>0.119132</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>65</td>\n",
              "      <td>0.114800</td>\n",
              "      <td>0.122896</td>\n",
              "      <td>0.125646</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>70</td>\n",
              "      <td>0.114800</td>\n",
              "      <td>0.123713</td>\n",
              "      <td>0.140984</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>75</td>\n",
              "      <td>0.114800</td>\n",
              "      <td>0.122272</td>\n",
              "      <td>0.135680</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>80</td>\n",
              "      <td>0.114800</td>\n",
              "      <td>0.122572</td>\n",
              "      <td>0.135696</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>85</td>\n",
              "      <td>0.114800</td>\n",
              "      <td>0.123067</td>\n",
              "      <td>0.139448</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>90</td>\n",
              "      <td>0.114800</td>\n",
              "      <td>0.129720</td>\n",
              "      <td>0.140223</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>95</td>\n",
              "      <td>0.114800</td>\n",
              "      <td>0.126045</td>\n",
              "      <td>0.132287</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>100</td>\n",
              "      <td>0.114800</td>\n",
              "      <td>0.121321</td>\n",
              "      <td>0.142023</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>105</td>\n",
              "      <td>0.114800</td>\n",
              "      <td>0.121252</td>\n",
              "      <td>0.142299</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>110</td>\n",
              "      <td>0.114800</td>\n",
              "      <td>0.117759</td>\n",
              "      <td>0.149029</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>115</td>\n",
              "      <td>0.114800</td>\n",
              "      <td>0.117840</td>\n",
              "      <td>0.147630</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>120</td>\n",
              "      <td>0.114800</td>\n",
              "      <td>0.122199</td>\n",
              "      <td>0.147464</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>125</td>\n",
              "      <td>0.114800</td>\n",
              "      <td>0.115782</td>\n",
              "      <td>0.154512</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>130</td>\n",
              "      <td>0.114800</td>\n",
              "      <td>0.123000</td>\n",
              "      <td>0.142951</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>135</td>\n",
              "      <td>0.114800</td>\n",
              "      <td>0.119753</td>\n",
              "      <td>0.146036</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>140</td>\n",
              "      <td>0.114800</td>\n",
              "      <td>0.122090</td>\n",
              "      <td>0.145805</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>145</td>\n",
              "      <td>0.114800</td>\n",
              "      <td>0.116000</td>\n",
              "      <td>0.149295</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>150</td>\n",
              "      <td>0.114800</td>\n",
              "      <td>0.114275</td>\n",
              "      <td>0.139438</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>155</td>\n",
              "      <td>0.114800</td>\n",
              "      <td>0.114197</td>\n",
              "      <td>0.151772</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>160</td>\n",
              "      <td>0.114800</td>\n",
              "      <td>0.119065</td>\n",
              "      <td>0.143172</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>165</td>\n",
              "      <td>0.114800</td>\n",
              "      <td>0.112483</td>\n",
              "      <td>0.152391</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>170</td>\n",
              "      <td>0.114800</td>\n",
              "      <td>0.112758</td>\n",
              "      <td>0.152269</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>175</td>\n",
              "      <td>0.114800</td>\n",
              "      <td>0.113298</td>\n",
              "      <td>0.149355</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>180</td>\n",
              "      <td>0.114800</td>\n",
              "      <td>0.112438</td>\n",
              "      <td>0.150092</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>185</td>\n",
              "      <td>0.114800</td>\n",
              "      <td>0.114862</td>\n",
              "      <td>0.152844</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>190</td>\n",
              "      <td>0.114800</td>\n",
              "      <td>0.112333</td>\n",
              "      <td>0.150061</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>195</td>\n",
              "      <td>0.114800</td>\n",
              "      <td>0.110669</td>\n",
              "      <td>0.152625</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>200</td>\n",
              "      <td>0.114800</td>\n",
              "      <td>0.109942</td>\n",
              "      <td>0.155348</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>205</td>\n",
              "      <td>0.114800</td>\n",
              "      <td>0.114199</td>\n",
              "      <td>0.153296</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>210</td>\n",
              "      <td>0.114800</td>\n",
              "      <td>0.111204</td>\n",
              "      <td>0.150396</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>215</td>\n",
              "      <td>0.114800</td>\n",
              "      <td>0.110145</td>\n",
              "      <td>0.145627</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>220</td>\n",
              "      <td>0.114800</td>\n",
              "      <td>0.111897</td>\n",
              "      <td>0.150698</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>225</td>\n",
              "      <td>0.114800</td>\n",
              "      <td>0.109742</td>\n",
              "      <td>0.152428</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>230</td>\n",
              "      <td>0.114800</td>\n",
              "      <td>0.109973</td>\n",
              "      <td>0.150266</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>235</td>\n",
              "      <td>0.114800</td>\n",
              "      <td>0.109750</td>\n",
              "      <td>0.152675</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>240</td>\n",
              "      <td>0.114800</td>\n",
              "      <td>0.110791</td>\n",
              "      <td>0.150883</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>245</td>\n",
              "      <td>0.114800</td>\n",
              "      <td>0.109889</td>\n",
              "      <td>0.148943</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>250</td>\n",
              "      <td>0.114800</td>\n",
              "      <td>0.109751</td>\n",
              "      <td>0.148858</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>255</td>\n",
              "      <td>0.114800</td>\n",
              "      <td>0.108809</td>\n",
              "      <td>0.150251</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>260</td>\n",
              "      <td>0.114800</td>\n",
              "      <td>0.108653</td>\n",
              "      <td>0.151353</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>265</td>\n",
              "      <td>0.114800</td>\n",
              "      <td>0.108436</td>\n",
              "      <td>0.151709</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>270</td>\n",
              "      <td>0.114800</td>\n",
              "      <td>0.108370</td>\n",
              "      <td>0.152384</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>275</td>\n",
              "      <td>0.114800</td>\n",
              "      <td>0.108367</td>\n",
              "      <td>0.151203</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>280</td>\n",
              "      <td>0.114800</td>\n",
              "      <td>0.108368</td>\n",
              "      <td>0.151268</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>285</td>\n",
              "      <td>0.114800</td>\n",
              "      <td>0.108455</td>\n",
              "      <td>0.151769</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>290</td>\n",
              "      <td>0.114800</td>\n",
              "      <td>0.108478</td>\n",
              "      <td>0.151688</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>295</td>\n",
              "      <td>0.114800</td>\n",
              "      <td>0.108458</td>\n",
              "      <td>0.151608</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>300</td>\n",
              "      <td>0.114800</td>\n",
              "      <td>0.108457</td>\n",
              "      <td>0.151624</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table><p>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": []
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(3248, 1)\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "    <div>\n",
              "      \n",
              "      <progress value='40' max='303' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
              "      [ 40/303 02:52 < 19:55, 0.22 it/s, Epoch 0.39/3]\n",
              "    </div>\n",
              "    <table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              " <tr style=\"text-align: left;\">\n",
              "      <th>Step</th>\n",
              "      <th>Training Loss</th>\n",
              "      <th>Validation Loss</th>\n",
              "      <th>Pauc80</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <td>5</td>\n",
              "      <td>0.147500</td>\n",
              "      <td>0.265498</td>\n",
              "      <td>0.101824</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>10</td>\n",
              "      <td>0.147500</td>\n",
              "      <td>0.819089</td>\n",
              "      <td>0.089112</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>15</td>\n",
              "      <td>0.147500</td>\n",
              "      <td>0.137750</td>\n",
              "      <td>0.076938</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>20</td>\n",
              "      <td>0.147500</td>\n",
              "      <td>0.297552</td>\n",
              "      <td>0.118953</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>25</td>\n",
              "      <td>0.147500</td>\n",
              "      <td>0.217045</td>\n",
              "      <td>0.097540</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>30</td>\n",
              "      <td>0.147500</td>\n",
              "      <td>0.137326</td>\n",
              "      <td>0.099606</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>35</td>\n",
              "      <td>0.147500</td>\n",
              "      <td>0.204485</td>\n",
              "      <td>0.124037</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table><p>"
            ]
          },
          "metadata": {}
        }
      ],
      "source": [
        "for CFG in all_config_list:\n",
        "    save_eval_step = int(CFG.save_eval_step_base / CFG.gradient_accumulation_steps)\n",
        "    if TEST_RUN:\n",
        "        data = data.sample(200).reset_index(drop=True)\n",
        "        save_eval_step = 5\n",
        "    print(save_eval_step)\n",
        "\n",
        "    training_args = TrainingArguments(\n",
        "        output_dir=f'output_{CFG.exp_ver}',\n",
        "        fp16=True,\n",
        "        learning_rate=CFG.lr,\n",
        "        gradient_accumulation_steps=CFG.gradient_accumulation_steps,\n",
        "        per_device_train_batch_size=CFG.train_batch_size,\n",
        "        per_device_eval_batch_size=CFG.eval_batch_size,\n",
        "        num_train_epochs=CFG.train_epochs,\n",
        "        weight_decay=CFG.weight_decay,\n",
        "\n",
        "        metric_for_best_model='pAUC80',\n",
        "        evaluation_strategy='steps',\n",
        "        eval_steps=save_eval_step,\n",
        "        save_strategy='steps',\n",
        "        save_steps=save_eval_step,\n",
        "        save_total_limit=1,\n",
        "        load_best_model_at_end=True,\n",
        "\n",
        "        report_to='none',\n",
        "        logging_first_step=True,\n",
        "\n",
        "        remove_unused_columns=False,\n",
        "    )\n",
        "\n",
        "    for fold in range(len(data[CFG.fold_type].unique())):\n",
        "        if ONLY_ONE_FOLD and fold > 0:\n",
        "            continue\n",
        "\n",
        "        if not os.path.exists(f'{COMMON_DIR}/output/v{CFG.exp_ver}/fold_{fold}'):\n",
        "            os.makedirs(f'{COMMON_DIR}/output/v{CFG.exp_ver}/fold_{fold}')\n",
        "\n",
        "        train = data[data[CFG.fold_type] != fold]\n",
        "        valid = data[data[CFG.fold_type] == fold].copy()\n",
        "\n",
        "        model = ISICModel(\n",
        "            backbone_type=CFG.model.backbone_type,\n",
        "            pooling_type=CFG.model.pooling_type,\n",
        "            num_classes=CFG.num_labels,\n",
        "            pretrained=CFG.model.pretrained,\n",
        "            checkpoint_path=None,\n",
        "            # checkpoint_path=CFG.model.checkpoint_path,\n",
        "            use_metadata=False,\n",
        "            # use_metadata=CFG.use_metadata,\n",
        "        )\n",
        "\n",
        "        device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
        "        model.to(device)\n",
        "\n",
        "        train_steps_per_epoch = int(len(train) / CFG.train_batch_size)\n",
        "        num_train_steps = train_steps_per_epoch * CFG.train_epochs\n",
        "\n",
        "        optimizer = get_optimizer(model, CFG)\n",
        "        scheduler = get_scheduler(optimizer, CFG, num_train_steps)\n",
        "\n",
        "        train_dataset = ISICDataset(train, is_train=True, transforms=get_img_transform(CFG, is_train=True))\n",
        "        valid_dataset = ISICDataset(valid, is_train=False, transforms=get_img_transform(CFG, is_train=False))\n",
        "\n",
        "        trainer = CustomTrainer(\n",
        "            cfg=CFG,\n",
        "            model=model,\n",
        "            args=training_args,\n",
        "            train_dataset=train_dataset,\n",
        "            eval_dataset=valid_dataset,\n",
        "            data_collator=collate_fn,\n",
        "            compute_metrics=compute_metrics,\n",
        "            optimizers=(optimizer, scheduler),\n",
        "        )\n",
        "\n",
        "        try:\n",
        "            trainer.train()\n",
        "        except Exception as e:\n",
        "            print(e)\n",
        "            from google.colab import runtime\n",
        "            runtime.unassign()\n",
        "\n",
        "        y_true = valid['target'].values\n",
        "        tmp_preds = trainer.predict(valid_dataset).predictions\n",
        "\n",
        "        try:\n",
        "            partial_auc = calculate_pAUC(y_true, tmp_preds)\n",
        "            param_sheet = ss.worksheet(\"パラメータv1\")\n",
        "            param_sheet.update_acell(f\"Z{CFG.exp_ver + 1}\", partial_auc)\n",
        "        except Exception as e:\n",
        "            print(e)\n",
        "\n",
        "        best_model = trainer.model\n",
        "        torch.save(\n",
        "            {'model': model.state_dict()},\n",
        "            f'{COMMON_DIR}/output/v{CFG.exp_ver}/fold_{fold}/best_model.pth',\n",
        "        )\n",
        "\n",
        "        valid['pred'] = tmp_preds\n",
        "        valid.to_csv(f'{COMMON_DIR}/output/v{CFG.exp_ver}/valid_df_fold_{fold}.csv', index=False)\n",
        "\n",
        "    # OOF Valid Score.\n",
        "    if not ONLY_ONE_FOLD:\n",
        "        dfs = []\n",
        "        for k in range(CFG.n_splits):\n",
        "            dfs.append( pd.read_csv(f'{COMMON_DIR}/output/v{CFG.exp_ver}/valid_df_fold_{k}.csv'))\n",
        "\n",
        "        dfs = pd.concat(dfs)\n",
        "        # Stacking用に保存しておく\n",
        "        dfs.to_csv(f'{COMMON_DIR}/output/v{CFG.exp_ver}/valid_df.csv',index=False)\n",
        "        print('Valid OOF shape:', dfs.shape )\n",
        "        display( dfs.head() )\n",
        "\n",
        "        m = calculate_pAUC(dfs.target.values, dfs['pred'].values)\n",
        "        print('Overall pAUC80 CV =',m)\n",
        "\n",
        "        try:\n",
        "            param_sheet = ss.worksheet(\"パラメータv1\")\n",
        "            param_sheet.update_acell(f\"W{CFG.exp_ver+1}\", m)\n",
        "        except Exception as e:\n",
        "            print(e)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "K_jl1JFVzp8i"
      },
      "outputs": [],
      "source": [
        "# from google.colab import runtime\n",
        "# runtime.unassign()\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "bjFPLN_EZsFC"
      },
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "L4",
      "machine_shape": "hm",
      "provenance": []
    },
    "kaggle": {
      "accelerator": "nvidiaTeslaT4",
      "dataSources": [
        {
          "databundleVersionId": 8059942,
          "sourceId": 71485,
          "sourceType": "competition"
        },
        {
          "datasetId": 2663421,
          "sourceId": 4620664,
          "sourceType": "datasetVersion"
        },
        {
          "datasetId": 4888887,
          "sourceId": 8241506,
          "sourceType": "datasetVersion"
        }
      ],
      "dockerImageVersionId": 30699,
      "isGpuEnabled": true,
      "isInternetEnabled": false,
      "language": "python",
      "sourceType": "notebook"
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.10.13"
    },
    "papermill": {
      "default_parameters": {},
      "duration": 7065.473945,
      "end_time": "2024-04-21T03:57:27.020454",
      "environment_variables": {},
      "exception": null,
      "input_path": "__notebook__.ipynb",
      "output_path": "__notebook__.ipynb",
      "parameters": {},
      "start_time": "2024-04-21T01:59:41.546509",
      "version": "2.5.0"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}